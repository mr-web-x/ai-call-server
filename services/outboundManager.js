import { CallSession } from './callSession.js';
import { AIServices } from './aiServices.js';
import { responseGenerator } from './responseGenerator.js';
import { DebtCollectionScripts } from '../scripts/debtCollection.js';
import { ttsManager } from './ttsManager.js';
import { audioManager } from './audioManager.js';
import { Call } from '../models/Call.js';
import { Client } from '../models/Client.js';
import { logger } from '../utils/logger.js';
import { CONFIG } from '../config/index.js';
import { whisperDetector } from '../utils/whisperHallucinationDetector.js';
import { silenceHandler } from './silenceHandler.js';
import { mediaStreamManager } from './mediaStreamManager.js';
import { sttQueue, llmQueue, ttsQueue } from '../queues/setup.js';

// üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π Twilio –∫–æ–Ω—Ñ–∏–≥
import { twilioClient, TWILIO_CONFIG } from '../config/twilio.js';

import axios from 'axios';

export class OutboundManager {
  // super();
  constructor() {
    this.activeCalls = new Map(); // callId -> callData
    this.pendingAudio = new Map(); // callId -> audioData
    this.recordingProcessing = new Map(); // callId -> boolean
    this.classificationTracker = new Map(); // callId -> { classification -> count }
    this.gptFailureCounter = new Map(); // callId -> failureCount
    this.conversationStages = new Map(); // callId -> stage info –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å—Ç–∞–¥–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä–∞

    // üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–π twilioClient
    this.twilioClient = twilioClient;

    this.pendingTwiml = new Map(); // callId -> pending TwiML
    this.streamingMetrics = new Map(); // callId -> latency metrics
    this.isStreamingEnabled = process.env.ENABLE_MEDIA_STREAMS === 'true';

    logger.info('üèóÔ∏è OutboundCallManager initialized');
  }

  /**
   *  –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–¥–∏—è–º–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
   */
  setConversationStage(callId, stage, audioInfo = null) {
    const stageData = {
      stage: stage,
      timestamp: Date.now(),
      audioInfo: audioInfo,
      lastTwiMLRequest: null,
    };

    this.conversationStages.set(callId, stageData);
    logger.info(`üé≠ Stage changed for ${callId}: ${stage}`);
  }

  getConversationStage(callId) {
    return this.conversationStages.get(callId);
  }

  /**
   * –ò–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ö–æ–¥—è—â–∏–π –∑–≤–æ–Ω–æ–∫
   */
  async initiateCall(clientId) {
    try {
      // üîç –û–¢–õ–ê–î–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –≤–∞—à–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞
      logger.info('üîç Twilio Configuration Debug:', {
        TWILIO_PHONE_NUMBER: TWILIO_CONFIG.phoneNumber
          ? TWILIO_CONFIG.phoneNumber
          : 'UNDEFINED',
        SERVER_URL: TWILIO_CONFIG.serverUrl || CONFIG.SERVER_URL,
        TIMEOUT: TWILIO_CONFIG.timeout,
      });

      // üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ TWILIO_CONFIG
      if (!TWILIO_CONFIG.phoneNumber) {
        throw new Error(
          'TWILIO_PHONE_NUMBER is missing in TWILIO_CONFIG - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ .env —Ñ–∞–π–ª!'
        );
      }

      // –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞
      const client = await Client.findById(clientId);
      if (!client) {
        throw new Error(`Client not found: ${clientId}`);
      }

      const callId = `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;

      logger.info(
        `üìû Starting call initiation for client: ${clientId} (${client.name})`
      );

      // –°–æ–∑–¥–∞—ë–º —Å–µ—Å—Å–∏—é –∑–≤–æ–Ω–∫–∞
      const session = new CallSession(callId, {
        name: client.name,
        phone: client.phone,
        amount: client.debt_amount,
        contract: client.contract_number,
        company: client.company || '–§–∏–Ω–∞–Ω—Å-–°–µ—Ä–≤–∏—Å',
      });

      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∑–≤–æ–Ω–∫–∞
      const callData = {
        callId,
        twilioSid: null,
        status: 'initiating',
        clientId,
        session,
        conversation: [],
        currentStage: 'start',
        startTime: Date.now(),
        recordingCount: 0,
        lastActivity: Date.now(),
        // üîß –î–û–ë–ê–í–õ–Ø–ï–ú: –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ø–µ—Ä–≤—ã–º —Ñ–∞–π–ª–æ–º
        twilioCallSid: null,
        phone: client.phone,
        greetingJobId: null,
        processingRecording: false,
      };

      this.activeCalls.set(callId, callData);

      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–∫–µ—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π
      this.classificationTracker.set(callId, {});
      this.gptFailureCounter.set(callId, 0);

      // –ü—Ä–µ–¥–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
      await this.preGenerateGreeting(callId);

      // –°–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å—å –≤ –ë–î
      await this.createCallRecord(callId, client);

      // üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
      const baseUrl =
        TWILIO_CONFIG.serverUrl ||
        CONFIG.SERVER_URL ||
        `http://localhost:${CONFIG.PORT || 3000}`;

      const callParams = {
        to: client.phone,
        from: TWILIO_CONFIG.phoneNumber,
        url: `${baseUrl}/api/webhooks/twiml`,
        statusCallback: `${baseUrl}/api/webhooks/status/${callId}`,
        statusCallbackEvent: ['initiated', 'ringing', 'answered', 'completed'],
        method: 'POST',
        record: false,
        timeout: TWILIO_CONFIG.timeout || 30,
      };

      logger.info('üîç Call parameters before Twilio API call:', {
        to: callParams.to,
        from: callParams.from,
        fromType: typeof callParams.from,
        fromLength: callParams.from ? callParams.from.length : 0,
        url: callParams.url,
        statusCallback: callParams.statusCallback,
      });

      // –ò–Ω–∏—Ü–∏–∏—Ä—É–µ–º –∑–≤–æ–Ω–æ–∫ —á–µ—Ä–µ–∑ Twilio
      const call = await this.twilioClient.calls.create(callParams);

      callData.twilioSid = call.sid;
      callData.twilioCallSid = call.sid; // üîß –î–û–ë–ê–í–õ–Ø–ï–ú: –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

      logger.info(`‚úÖ Call initiated: ${callId} -> Twilio SID: ${call.sid}`);
      logger.info('üìû TwiML URL will be handled by Console settings');

      return {
        success: true,
        callId,
        twilioSid: call.sid,
        twilioCallSid: call.sid, // üîß –î–û–ë–ê–í–õ–Ø–ï–ú: –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        clientName: client.name,
        phone: client.phone,
        status: 'initiated',
      };
    } catch (error) {
      logger.error('‚ùå Call initiation failed:', error);
      logger.error('‚ùå Error details:', {
        message: error.message,
        code: error.code,
        status: error.status,
      });
      throw error;
    }
  }

  /**
   * Get active call data
   */
  getActiveCall(callId) {
    return this.activeCalls.get(callId);
  }

  /**
   * Generate error TwiML (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –ø–µ—Ä–≤—ã–º —Ñ–∞–π–ª–æ–º)
   */
  generateErrorTwiML() {
    logger.warn(`‚ö†Ô∏è Generating error TwiML`);
    return `<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say voice="Polly.Maxim" language="ru-RU">–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –î–æ —Å–≤–∏–¥–∞–Ω–∏—è.</Say>
    <Hangup/>
</Response>`;
  }

  /**
   * Get all active calls summary (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –ø–µ—Ä–≤—ã–º —Ñ–∞–π–ª–æ–º)
   */
  getAllActiveCalls() {
    return Array.from(this.activeCalls.entries()).map(([callId, data]) => ({
      callId,
      clientId: data.clientId,
      phone: data.phone,
      status: data.status,
      currentStage: data.currentStage,
      startTime: new Date(data.startTime),
      duration: Date.now() - data.startTime,
      hasAudio: this.pendingAudio.has(callId),
      twilioCallSid: data.twilioCallSid || data.twilioSid,
    }));
  }

  /**
   * Get call metrics and statistics (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –ø–µ—Ä–≤—ã–º —Ñ–∞–π–ª–æ–º)
   */
  getCallMetrics() {
    const activeCalls = this.getAllActiveCalls();
    const byStatus = activeCalls.reduce((acc, call) => {
      acc[call.status] = (acc[call.status] || 0) + 1;
      return acc;
    }, {});

    return {
      total: activeCalls.length,
      byStatus,
      pendingAudio: this.pendingAudio.size,
      longestCall:
        activeCalls.length > 0
          ? Math.max(...activeCalls.map((call) => call.duration))
          : 0,
    };
  }

  /**
   * Handle TTS completion and store audio data (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –ø–µ—Ä–≤—ã–º —Ñ–∞–π–ª–æ–º)
   */
  handleTTSCompleted(callId, audioData) {
    logger.info(`üéØ TTS COMPLETED for call ${callId}:`, {
      source: audioData.source,
      hasAudioUrl: !!audioData.audioUrl,
      hasAudioBuffer: !!audioData.audioBuffer,
      twilioTTS: audioData.twilioTTS,
      type: audioData.type,
      voiceId: audioData.voiceId,
    });

    // Store audio data for webhook
    this.pendingAudio.set(callId, {
      ...audioData,
      timestamp: Date.now(),
      consumed: false,
    });

    logger.info(
      `‚úÖ TTS completed for call ${callId}, audio ready: ${audioData.source}`
    );

    // Notify when greeting is ready
    if (
      audioData.type === 'greeting' &&
      this.activeCalls.get(callId)?.status === 'calling'
    ) {
      logger.info(
        `üéâ Greeting ready for call ${callId} - ${audioData.source} audio prepared!`
      );
    }
  }

  /**
   * Check if TTS is still in progress for a call (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –ø–µ—Ä–≤—ã–º —Ñ–∞–π–ª–æ–º)
   */
  checkTTSInProgress(callId) {
    const callData = this.activeCalls.get(callId);
    if (!callData) return false;

    // Check if greeting job exists but audio is not ready yet
    return callData.greetingJobId && !this.pendingAudio.has(callId);
  }

  /**
   * –ü—Ä–µ–¥–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è
   */
  async preGenerateGreeting(callId) {
    try {
      const callData = this.activeCalls.get(callId);
      if (!callData) return;

      const greetingScript = DebtCollectionScripts.getScript(
        'start',
        'positive',
        callData.session.clientData
      );

      logger.info(`Greeting pre-generated for call: ${callId}`);

      // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º TTS –¥–ª—è –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è
      await this.generateResponseTTS(
        callId,
        greetingScript.text,
        'urgent',
        'greeting'
      );

      logger.info(`üéâ Greeting ready for call ${callId} - audio prepared!`);
    } catch (error) {
      logger.error(`Error pre-generating greeting for ${callId}:`, error);
    }
  }

  /**
   * –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∑–≤–æ–Ω–∫–∞ –≤ –ë–î
   */
  async createCallRecord(callId, client) {
    try {
      const callRecord = new Call({
        call_id: callId,
        client_id: client._id,
        client_name: client.name,
        client_phone: client.phone,
        debt_amount: client.debt_amount,
        status: 'initiated',
        start_time: new Date(),
        conversation: [],
        current_stage: 'start',
      });

      await callRecord.save();
      logger.info(
        `‚úÖ Call record created in DB: ${callId} for client: ${client._id}`
      );
    } catch (error) {
      logger.error(`‚ùå Failed to create call record for ${callId}:`, error);
    }
  }

  /**
   * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS –¥–ª—è –æ—Ç–≤–µ—Ç–∞
   */
  async generateResponseTTS(
    callId,
    text,
    priority = 'normal',
    type = 'response'
  ) {
    try {
      logger.info(
        `Generating ${type} TTS for call ${callId}: ${text.substring(0, 50)}...`
      );

      const result = await ttsManager.synthesizeSpeech(text, {
        priority,
        voiceId: CONFIG.ELEVENLABS_VOICE_ID,
        useCache: type === 'greeting' || priority === 'urgent',
      });

      if (result.audioBuffer || result.audioUrl) {
        let audioUrl = result.audioUrl;

        // –ï—Å–ª–∏ –µ—Å—Ç—å buffer, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ñ–∞–π–ª
        if (result.audioBuffer && !audioUrl) {
          const audioFile = await audioManager.saveAudioFile(
            callId,
            result.audioBuffer,
            type
          );
          audioUrl = audioFile.publicUrl;
        }

        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–æ—Ç–æ–≤–æ–µ –∞—É–¥–∏–æ
        this.pendingAudio.set(callId, {
          audioUrl,
          audioBuffer: result.audioBuffer,
          source: result.source,
          type,
          timestamp: Date.now(),
          consumed: false,
        });

        logger.info(`Audio saved for call ${callId} (${type}): ${audioUrl}`);
        return { success: true, audioUrl, source: result.source };
      }

      throw new Error('No audio generated');
    } catch (error) {
      logger.error(`‚ùå TTS generation failed for call ${callId}:`, error);
      return { success: false, error: error.message };
    }
  }

  /**
   * –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
   */
  async processRecording(callId, recordingUrl, recordingDuration) {
    const callData = this.activeCalls.get(callId);
    if (!callData) {
      logger.error(
        `Cannot process recording: call data not found for ${callId}`
      );
      return null;
    }

    let audioBuffer = null;

    try {
      logger.info(`üß† Starting enhanced AI processing for call: ${callId}`);
      logger.info(`üé§ Processing recording: ${recordingUrl}`);

      // üì• –°–ö–ê–ß–ò–í–ê–ï–ú –ê–£–î–ò–û
      audioBuffer = await this.downloadRecording(recordingUrl);
      if (!audioBuffer || audioBuffer.length === 0) {
        throw new Error('Failed to download or empty audio buffer');
      }

      // üíæ –°–û–•–†–ê–ù–Ø–ï–ú –î–õ–Ø –û–¢–õ–ê–î–ö–ò
      let audioPath = null;
      try {
        if (audioManager.saveRecordingForDebug) {
          audioPath = await audioManager.saveRecordingForDebug(
            callId,
            audioBuffer,
            recordingDuration
          );
        } else {
          const audioFile = await audioManager.saveAudioFile(
            callId,
            audioBuffer,
            'recording'
          );
          audioPath = audioFile.filepath;
        }
        logger.info(`üíæ Audio saved for debug: ${audioPath}`);
      } catch (saveError) {
        logger.warn(`‚ö†Ô∏è Failed to save audio for debug: ${saveError.message}`);
      }

      // üó£Ô∏è –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø –ß–ï–†–ï–ó WHISPER
      const transcriptionStart = Date.now();
      const transcriptionResult = await AIServices.transcribeAudio(audioBuffer);
      const transcriptionTime = Date.now() - transcriptionStart;

      const transcription = transcriptionResult.text?.trim() || '';

      logger.info(`üéØ TRANSCRIPTION RESULT for call ${callId}:`, {
        text: transcription,
        audioSize: `${(audioBuffer.length / 1024).toFixed(1)} KB`,
        duration: `${recordingDuration}s`,
        transcriptionTime: `${transcriptionTime}ms`,
        charCount: transcription.length,
        wordCount: transcription.split(' ').filter((w) => w.length > 0).length,
      });

      // üé≠ –ê–ù–ê–õ–ò–ó –ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ô WHISPER
      const whisperAnalysis = whisperDetector.analyzeTranscription(
        transcription,
        audioBuffer.length,
        recordingDuration
      );

      // üîá –û–ë–†–ê–ë–û–¢–ö–ê –ú–û–õ–ß–ê–ù–ò–Ø/–ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ô
      if (whisperAnalysis.isHallucination || whisperAnalysis.isSilence) {
        logger.info(`üîá Detected silence/hallucination for call ${callId}:`, {
          type: whisperAnalysis.isHallucination ? 'hallucination' : 'silence',
          confidence: `${Math.round(whisperAnalysis.confidence * 100)}%`,
          reasons: whisperAnalysis.reasons,
          recommendation: whisperAnalysis.recommendation,
        });

        // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ SilenceHandler
        const silenceResult = await silenceHandler.integrateWithPipeline(
          callId,
          {
            isHallucination: whisperAnalysis.isHallucination,
            isSilence: whisperAnalysis.isSilence,
            transcription: transcription,
          },
          audioBuffer.length,
          recordingDuration
        );

        if (silenceResult && silenceResult.action === 'respond') {
          // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º TTS –æ—Ç–≤–µ—Ç –Ω–∞ –º–æ–ª—á–∞–Ω–∏–µ
          return {
            success: true,
            classification: 'silence',
            response: silenceResult.response,
            nextStage: silenceResult.nextStage,
            shouldContinue: silenceResult.shouldContinue,
            metadata: {
              silenceType: silenceResult.silenceType,
              whisperAnalysis,
              silenceMetadata: silenceResult.metadata,
            },
          };
        } else {
          // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∂–¥–∞—Ç—å
          return {
            success: true,
            classification: 'ignored_silence',
            response: null,
            nextStage: 'listening',
            shouldContinue: true,
            metadata: {
              silenceType: silenceResult?.silenceType || 'unknown',
              whisperAnalysis,
              ignored: true,
              reason: silenceResult?.reason || 'Whisper hallucination',
            },
          };
        }
      }

      // ‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ß–¨ - –ü–†–û–î–û–õ–ñ–ê–ï–ú –ù–û–†–ú–ê–õ–¨–ù–£–Æ –û–ë–†–ê–ë–û–¢–ö–£
      logger.info(
        `üó£Ô∏è Real speech detected for call ${callId}, proceeding with normal pipeline`
      );

      // –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
      const conversationHistory = callData.conversationHistory || [];
      const currentStage = callData.currentStage || 'listening';

      // –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
      logger.info(
        `üîç Classifying response for call ${callId}: "${transcription.substring(0, 50)}..."`
      );

      const classificationResult = await AIServices.classifyResponse(
        transcription,
        currentStage,
        conversationHistory
      );

      const classification = classificationResult.classification || 'neutral';
      logger.info(`üè∑Ô∏è Classification result: ${classification}`);

      // –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
      const repeatCount = this.updateClassificationTracker(
        callId,
        classification
      );

      // –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
      conversationHistory.push(transcription);
      callData.conversationHistory = conversationHistory;

      // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
      logger.info(`üß† Generating AI response for ${callId}`);
      const responseResult = await responseGenerator.generateResponse({
        callId,
        clientData: callData.clientData,
        clientMessage: transcription,
        classification,
        conversationHistory,
        currentStage,
        repeatCount,
      });

      if (!responseResult.success) {
        throw new Error(`Response generation failed: ${responseResult.error}`);
      }

      // –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç AI –≤ –∏—Å—Ç–æ—Ä–∏—é
      conversationHistory.push(responseResult.response);
      callData.conversationHistory = conversationHistory;

      // –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞–¥–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
      callData.currentStage = responseResult.nextStage;

      // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º TTS
      logger.info(
        `üéµ Generating TTS for response: "${responseResult.response}"`
      );

      const ttsJob = await ttsQueue.add('synthesize', {
        text: responseResult.response,
        callId: callId,
        priority: 'normal',
        type: 'conversation',
        voiceId: process.env.TTS_VOICE_ID,
        useCache: true,
      });

      const ttsResult = await ttsJob.finished();

      if (ttsResult && (ttsResult.audioUrl || ttsResult.audioBuffer)) {
        this.pendingAudio.set(callId, {
          audioUrl: ttsResult.audioUrl,
          audioBuffer: ttsResult.audioBuffer,
          source: ttsResult.source,
          type: 'conversation',
          timestamp: Date.now(),
          consumed: false,
        });

        logger.info(
          `üéµ TTS audio ready for call ${callId}: ${ttsResult.source}`
        );
      } else {
        logger.warn(`‚ö†Ô∏è TTS generation failed for call ${callId}`);
      }

      return {
        success: true,
        classification,
        response: responseResult.response,
        nextStage: responseResult.nextStage,
        shouldContinue: responseResult.nextStage !== 'completed',
        metadata: {
          transcription,
          repeatCount,
          whisperAnalysis,
          realSpeech: true,
          processingTime: {
            transcription: transcriptionTime,
            total: Date.now() - transcriptionStart,
          },
        },
      };
    } catch (error) {
      logger.error(
        `‚ùå Enhanced recording processing error for call ${callId}:`,
        {
          error: error.message,
          stack: error.stack?.split('\n')[0],
          audioSize: audioBuffer?.length || 0,
          duration: recordingDuration,
        }
      );

      // Fallback –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
      return this.handleRecordingError(callId, error);
    }
  }

  /**
   * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É
   */
  async generateAdvancedResponse(responseContext) {
    const { callId } = responseContext;

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ—É–¥–∞—á GPT –¥–ª—è —ç—Ç–æ–≥–æ –∑–≤–æ–Ω–∫–∞
      const gptFailures = this.gptFailureCounter.get(callId) || 0;

      if (gptFailures >= CONFIG.MAX_GPT_FAILURES_BEFORE_FALLBACK) {
        logger.warn(
          `‚ö†Ô∏è Too many GPT failures for call ${callId}, forcing script mode`
        );
        return this.generateScriptResponse(responseContext);
      }

      // –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å responseGenerator
      const response =
        await responseGenerator.generateResponse(responseContext);

      // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
      this.gptFailureCounter.set(callId, 0);

      return response;
    } catch (error) {
      logger.error(
        `‚ùå Advanced response generation failed for call ${callId}:`,
        error
      );

      // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á
      const currentFailures = this.gptFailureCounter.get(callId) || 0;
      this.gptFailureCounter.set(callId, currentFailures + 1);

      // –§–æ–ª–±—ç–∫ –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
      return this.generateScriptResponse(responseContext);
    }
  }

  /**
   * –§–æ–ª–±—ç–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç—ã
   */
  generateScriptResponse(responseContext) {
    const { classification, currentStage, clientData, repeatCount } =
      responseContext;

    logger.info(
      `üìú Using script fallback for classification: ${classification}`
    );

    // –ü–æ–ª—É—á–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
    const responseVariants = DebtCollectionScripts.getResponseVariants(
      currentStage,
      classification,
      clientData
    );

    // –í—ã–±–∏—Ä–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
    const variantIndex = Math.min(repeatCount, responseVariants.length - 1);
    const selectedResponse =
      responseVariants[variantIndex] || responseVariants[0];

    return {
      text: selectedResponse.text,
      nextStage: selectedResponse.nextStage,
      method: 'script',
      isValid: true,
    };
  }

  /**
   * –¢—Ä–µ–∫–∏–Ω–≥ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π
   */
  updateClassificationTracker(callId, classification) {
    if (!this.classificationTracker.has(callId)) {
      this.classificationTracker.set(callId, {});
    }

    const callTracker = this.classificationTracker.get(callId);
    const currentCount = callTracker[classification] || 0;
    const newCount = currentCount + 1;

    callTracker[classification] = newCount;

    logger.info(`üìä Classification tracking for call ${callId}:`, {
      classification,
      count: newCount,
      allClassifications: callTracker,
    });

    return newCount - 1; // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
  }

  /**
   * –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏
   */
  async downloadRecording(recordingUrl) {
    try {
      const maxRetries = 3;
      let lastError;

      for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
          if (attempt > 1) {
            logger.warn(
              `‚è∞ Recording not ready yet, waiting 3 more seconds...`
            );
            await new Promise((resolve) => setTimeout(resolve, 1000));
          }

          const response = await axios.get(recordingUrl, {
            responseType: 'arraybuffer',
            headers: {
              'User-Agent': 'DebtCollection-AI/1.0',
            },
            timeout: 30000,
            auth: {
              username: process.env.TWILIO_ACCOUNT_SID,
              password: process.env.TWILIO_AUTH_TOKEN,
            },
          });

          if (response.data && response.data.byteLength > 1000) {
            const message =
              attempt > 1
                ? `‚úÖ Recording downloaded on retry: ${response.data.byteLength} bytes`
                : `‚úÖ Recording downloaded: ${response.data.byteLength} bytes`;
            logger.info(message);

            return Buffer.from(response.data);
          }

          throw new Error(
            `Recording too small: ${response.data?.byteLength || 0} bytes`
          );
        } catch (error) {
          lastError = error;
          if (attempt === maxRetries) {
            throw error;
          }
          logger.warn(
            `‚ö†Ô∏è Download attempt ${attempt} failed: ${error.message}`
          );
        }
      }

      throw lastError;
    } catch (error) {
      logger.error('‚ùå Failed to download recording:', error);
      throw error;
    }
  }

  /**
   * –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∑–∞–ø–∏—Å–∏
   */
  handleRecordingError(callId, error) {
    logger.warn(
      `‚ö†Ô∏è Using enhanced fallback for call ${callId} due to error:`,
      error.message
    );

    const fallbackResponse =
      '–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Ä–∞—Å—Å–ª—ã—à–∞–ª. –ù–µ –º–æ–≥–ª–∏ –±—ã –≤—ã –ø–æ–≤—Ç–æ—Ä–∏—Ç—å?';

    // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º TTS –¥–ª—è —Ñ–æ–ª–±—ç–∫–∞
    this.generateResponseTTS(callId, fallbackResponse, 'urgent');

    return {
      transcription: '[ERROR: Could not process audio]',
      classification: 'unclear',
      response: fallbackResponse,
      nextStage: 'listening',
      method: 'fallback',
      error: true,
    };
  }

  /**
   * –ü–æ–ª—É—á–∏—Ç—å pending audio –¥–ª—è –∑–≤–æ–Ω–∫–∞
   */
  getPendingAudio(callId) {
    return this.pendingAudio.get(callId);
  }

  /**
   * –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ pending audio
   */
  hasPendingAudio(callId) {
    const audio = this.pendingAudio.get(callId);
    return audio && !audio.consumed;
  }

  /**
   * –°–≤—è–∑–∞—Ç—å Media Stream —Å –∑–≤–æ–Ω–∫–æ–º
   */
  linkMediaStream(callId, streamSid) {
    const callData = this.activeCalls.get(callId);
    if (callData) {
      callData.streamSid = streamSid;
      logger.info(`üîó Linked media stream ${streamSid} to call ${callId}`);
    }
  }

  hasActiveCall(callId) {
    return this.activeCalls.has(callId);
  }

  /**
   * –û–ë–ù–û–í–õ–ï–ù–ù–´–ô generateTwiML –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ callId –≤ Stream
   */
  generateTwiML(callId, type = 'initial') {
    const callData = this.activeCalls.get(callId);
    if (!callData) {
      logger.error(`No call data for TwiML generation: ${callId}`);
      return this.generateErrorTwiML();
    }

    const webhookUrl = `${process.env.SERVER_URL}/api/webhooks`;
    const voice = 'Polly.Tatyana';

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∫–ª—é—á–µ–Ω –ª–∏ streaming
    const isStreamingEnabled = process.env.ENABLE_MEDIA_STREAMS === 'true';

    let twiml = '<?xml version="1.0" encoding="UTF-8"?><Response>';

    // –í–∫–ª—é—á–∞–µ–º Media Streams –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
    if (isStreamingEnabled && type === 'initial') {
      const streamUrl =
        process.env.SERVER_URL.replace('https://', 'wss://') + '/media-stream';

      // –í–ê–ñ–ù–û: –ø–µ—Ä–µ–¥–∞–µ–º callId —á–µ—Ä–µ–∑ customParameters
      twiml += `<Start>
      <Stream url="${streamUrl}" track="outbound">
        <Parameter name="callId" value="${callId}" />
        <Parameter name="twilioSid" value="${callData.twilioSid || callData.twilioCallSid}" />
      </Stream>
    </Start>`;
    }

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º pending audio
    const pendingAudio = this.pendingAudio.get(callId);

    if (pendingAudio && !pendingAudio.consumed) {
      // –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –∞—É–¥–∏–æ
      if (pendingAudio.audioUrl) {
        twiml += `<Play>${pendingAudio.audioUrl}</Play>`;
        logger.info(`üéµ Playing audio: ${pendingAudio.audioUrl}`);
      } else {
        const text = pendingAudio.text || '–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ';
        twiml += `<Say voice="${voice}" language="ru-RU">${text}</Say>`;
      }

      pendingAudio.consumed = true;
    }

    // –î–ª—è streaming –∏—Å–ø–æ–ª—å–∑—É–µ–º Pause –≤–º–µ—Å—Ç–æ Record
    if (isStreamingEnabled) {
      twiml += `<Pause length="30"/>`;
      twiml += `<Redirect>${webhookUrl}/continue/${callId}</Redirect>`;
    } else {
      // Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π Record API
      twiml += `<Record
      action="${webhookUrl}/recording/${callId}"
      recordingStatusCallback="${webhookUrl}/recording-status/${callId}"
      timeout="3"
      maxLength="30"
      finishOnKey="#"
      playBeep="false"
      trim="trim-silence"
    />`;
      twiml += `<Redirect>${webhookUrl}/continue/${callId}</Redirect>`;
    }

    twiml += '</Response>';

    logger.info(
      `üìã Generated ${isStreamingEnabled ? 'STREAMING' : 'RECORDING'} TwiML for ${callId}`
    );
    return twiml;
  }

  /**
   * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TwiML –æ—Ç–≤–µ—Ç–∞
   */
  // generateTwiML(callId, type = 'initial') {
  //   const callData = this.activeCalls.get(callId);
  //   if (!callData) {
  //     logger.error(`No call data for TwiML generation: ${callId}`);
  //     return this.generateErrorTwiML();
  //   }

  //   const webhookUrl = `${process.env.SERVER_URL}/api/webhooks`;
  //   const voice = 'Polly.Tatyana';

  //   let twiml = '<?xml version="1.0" encoding="UTF-8"?><Response>';

  //   // –í–∫–ª—é—á–∞–µ–º Media Streams –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
  //   if (this.isStreamingEnabled && type === 'initial') {
  //     const streamUrl =
  //       process.env.SERVER_URL.replace('https://', 'wss://') + '/media-stream';

  //     twiml += `<Start>
  //       <Stream url="${streamUrl}">
  //         <Parameter name="callId" value="${callId}" />
  //         <Parameter name="twilioSid" value="${callData.twilioSid}" />
  //       </Stream>
  //     </Start>`;
  //   }

  //   // –ü—Ä–æ–≤–µ—Ä—è–µ–º pending audio
  //   const pendingAudio = this.pendingAudio.get(callId);

  //   if (pendingAudio && !pendingAudio.consumed) {
  //     // –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –∞—É–¥–∏–æ
  //     if (pendingAudio.audioUrl) {
  //       twiml += `<Play>${pendingAudio.audioUrl}</Play>`;
  //     } else {
  //       const text = pendingAudio.text || '–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ';
  //       twiml += `<Say voice="${voice}" language="ru-RU">${text}</Say>`;
  //     }

  //     pendingAudio.consumed = true;
  //   }

  //   // –î–ª—è streaming –∏—Å–ø–æ–ª—å–∑—É–µ–º Pause –≤–º–µ—Å—Ç–æ Record
  //   if (this.isStreamingEnabled) {
  //     twiml += `<Pause length="30"/>`;
  //     twiml += `<Redirect>${webhookUrl}/continue/${callId}</Redirect>`;
  //   } else {
  //     // Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π Record API
  //     twiml += `<Record
  //       action="${webhookUrl}/recording/${callId}"
  //       recordingStatusCallback="${webhookUrl}/recording-status/${callId}"
  //       timeout="3"
  //       maxLength="30"
  //       finishOnKey="#"
  //       playBeep="false"
  //       trim="trim-silence"
  //     />`;
  //     twiml += `<Redirect>${webhookUrl}/continue/${callId}</Redirect>`;
  //   }

  //   twiml += '</Response>';

  //   logger.info(
  //     `üìã Generated ${this.isStreamingEnabled ? 'STREAMING' : 'RECORDING'} TwiML for ${callId}`
  //   );
  //   return twiml;
  // }

  // generateTwiML(callId, context = 'initial') {
  //   const callData = this.activeCalls.get(callId);
  //   if (!callData) {
  //     logger.error(`Call data not found for TwiML generation: ${callId}`);
  //     return this.generateErrorTwiML(); // ‚úÖ –≠–¢–û –£–ñ–ï –ï–°–¢–¨!
  //   }

  //   // üéØ –ü–û–õ–£–ß–ê–ï–ú –¢–ï–ö–£–©–£–Æ –°–¢–ê–î–ò–Æ
  //   const stageData = this.getConversationStage(callId);
  //   const currentStage = stageData?.stage || 'start';

  //   logger.info(`üé≠ TwiML for ${callId}, stage: ${currentStage}`);

  //   // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–æ–µ –∞—É–¥–∏–æ
  //   const audioData = this.pendingAudio.get(callId);
  //   logger.info(`üîç Checking pendingAudio for ${callId}:`, {
  //     hasAudioData: !!audioData,
  //     audioType: audioData?.type || 'none',
  //     consumed: audioData?.consumed || false,
  //     audioUrl: audioData?.audioUrl ? 'present' : 'missing',
  //   });

  //   if (audioData && !audioData.consumed) {
  //     logger.info(`üéµ Using ready audio for call: ${callId}`);

  //     // –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ
  //     audioData.consumed = true;
  //     this.pendingAudio.set(callId, audioData);

  //     // üéØ –£–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú –°–¢–ê–î–ò–Æ
  //     if (currentStage === 'start') {
  //       this.setConversationStage(callId, 'greeting_sent', {
  //         audioUrl: audioData.audioUrl,
  //         source: audioData.source,
  //       });
  //     } else {
  //       // silence_response, conversation, response - –≤—Å–µ –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç
  //       this.setConversationStage(callId, 'response_sent', {
  //         audioUrl: audioData.audioUrl,
  //         source: audioData.source,
  //       });
  //     }

  //     if (audioData.audioUrl) {
  //       logger.info(`üéµ Sending ElevenLabs PLAY TwiML for call: ${callId}`);
  //       logger.info(`üéµ Audio URL: ${audioData.audioUrl}`);
  //       return this.generatePlayTwiML(callId, audioData.audioUrl); // ‚úÖ –≠–¢–û –£–ñ–ï –ï–°–¢–¨!
  //     }
  //   }

  //   // üéØ –û–ë–ù–û–í–õ–ï–ù–ù–´–ô FALLBACK (—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ª–æ–≥–∏–∫–∞)
  //   const script = DebtCollectionScripts.getScript(
  //     callData.currentStage || 'start',
  //     'positive',
  //     callData.session.clientData
  //   );

  //   logger.warn(`‚ö†Ô∏è No audio ready for call: ${callId}, using fallback TTS`);

  //   // üéØ –£–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú –°–¢–ê–î–ò–Æ –î–õ–Ø FALLBACK
  //   if (currentStage === 'start') {
  //     this.setConversationStage(callId, 'greeting_sent', {
  //       source: 'twilio_fallback',
  //     });
  //   }

  //   return this.generateSayTwiML(callId, script.text, 'Polly.Maxim'); // ‚úÖ –ò–∑–º–µ–Ω–∏–ª–∏ –≥–æ–ª–æ—Å –Ω–∞ –º—É–∂—Å–∫–æ–π
  // }

  /**
   * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Play TwiML –¥–ª—è ElevenLabs
   */
  generatePlayTwiML(callId, audioUrl) {
    logger.info(`üéµ Generating Play TwiML for ElevenLabs audio: ${audioUrl}`);
    logger.info(`üéµ Sending PLAY TwiML (ElevenLabs) for call: ${callId}`);
    logger.info(`üéµ Audio URL: ${audioUrl}`);

    const twiml = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Play>${audioUrl}</Play>
<Record 
    action="${TWILIO_CONFIG.serverUrl}/api/webhooks/recording/${callId}"
    method="POST"
    maxLength="60"       
    playBeep="false"
    timeout="3"          
    finishOnKey="#"
    trim="trim-silence"  
    recordingStatusCallback="${TWILIO_CONFIG.serverUrl}/api/webhooks/recording-status/${callId}"
/>
</Response>`;

    logger.info(`üìã Full TwiML response for call ${callId}:`);
    logger.info(twiml);

    return twiml;
  }

  async processTranscriptionStreaming(callId, transcription) {
    const callData = this.activeCalls.get(callId);
    if (!callData) {
      logger.error(
        `Cannot process transcription: call data not found for ${callId}`
      );
      return null;
    }

    try {
      logger.info(`üìù Processing streaming transcription: "${transcription}"`);

      // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
      const currentStage = callData.currentStage || 'initial';
      const conversationHistory = callData.conversationHistory || [];

      // –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
      const classificationResult = await classificationService.classifyMessage(
        transcription,
        callData.clientData,
        currentStage,
        conversationHistory
      );

      const classification = classificationResult.classification || 'neutral';
      const repeatCount = this.updateClassificationTracker(
        callId,
        classification
      );

      // –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
      conversationHistory.push(transcription);
      callData.conversationHistory = conversationHistory;

      // –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
      const responseResult = await responseGenerator.generateResponse({
        callId,
        clientData: callData.clientData,
        clientMessage: transcription,
        classification,
        conversationHistory,
        currentStage,
        repeatCount,
      });

      if (!responseResult.success) {
        throw new Error(`Response generation failed: ${responseResult.error}`);
      }

      // –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏ —Å—Ç–∞–¥–∏—é
      conversationHistory.push(responseResult.response);
      callData.conversationHistory = conversationHistory;
      callData.currentStage = responseResult.nextStage;

      return {
        text: responseResult.response,
        classification,
        nextStage: responseResult.nextStage,
        emotion: responseResult.emotion || 'neutral',
      };
    } catch (error) {
      logger.error(`‚ùå Transcription processing error for ${callId}:`, error);
      return {
        text: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.',
        classification: 'error',
        emotion: 'apologetic',
      };
    }
  }

  /**
   * –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ö–æ–¥–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
   */
  async saveConversationTurn(callId, turnData) {
    try {
      await Call.findOneAndUpdate(
        { call_id: callId },
        {
          $push: {
            conversation_turns: {
              timestamp: new Date(),
              user_message: turnData.userMessage,
              classification: turnData.classification,
              ai_response: turnData.aiResponse,
              next_stage: turnData.nextStage,
              processing_time: turnData.processingTime,
              is_streaming: turnData.isStreaming,
            },
          },
          current_stage: turnData.nextStage,
          updated_at: new Date(),
        }
      );
    } catch (error) {
      logger.error(`Failed to save conversation turn for ${callId}:`, error);
    }
  }

  async processStreamingAudio(callId, audioBuffer) {
    const startTime = Date.now();
    this.streamingMetrics.set(callId, { startTime });

    const callData = this.activeCalls.get(callId);
    if (!callData) {
      logger.error(`No call data for streaming audio: ${callId}`);
      return;
    }

    try {
      // 1. Speech-to-Text
      const sttStart = Date.now();
      const transcription = await sttService.transcribe({
        audioBuffer,
        language: 'ru-RU',
        format: 'wav',
      });

      const sttDuration = Date.now() - sttStart;
      logger.info(`üé§ STT completed in ${sttDuration}ms: "${transcription}"`);

      if (!transcription || transcription.trim().length < 3) {
        logger.info(`ü§´ Empty transcription, ignoring`);
        return;
      }

      // 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ AI
      const aiStart = Date.now();
      const aiResponse = await this.processTranscriptionStreaming(
        callId,
        transcription
      );

      const aiDuration = Date.now() - aiStart;
      logger.info(`üß† AI response in ${aiDuration}ms: "${aiResponse.text}"`);

      // 3. –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
      callData.session.turns.push({
        user: transcription,
        assistant: aiResponse.text,
        classification: aiResponse.classification,
        timestamp: new Date(),
      });

      // 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS
      const ttsStart = Date.now();
      await this.generateResponseTTS(
        callId,
        aiResponse.text,
        aiResponse.priority || 'normal',
        aiResponse.type
      );

      const ttsDuration = Date.now() - ttsStart;
      const totalDuration = Date.now() - startTime;

      // 5. –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
      logger.info(`‚è±Ô∏è Streaming processing metrics for ${callId}:`, {
        stt: `${sttDuration}ms`,
        ai: `${aiDuration}ms`,
        tts: `${ttsDuration}ms`,
        total: `${totalDuration}ms`,
      });

      // 6. –¢—Ä–∏–≥–≥–µ—Ä–∏–º webhook update –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∞—É–¥–∏–æ
      this.triggerPlayback(callId);
    } catch (error) {
      logger.error(`‚ùå Streaming processing error for ${callId}:`, error);

      // Fallback –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
      await this.generateResponseTTS(
        callId,
        '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.',
        'urgent'
      );
    }
  }

  /**
   *  –¢—Ä–∏–≥–≥–µ—Ä –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ webhook
   */
  triggerPlayback(callId) {
    const callData = this.activeCalls.get(callId);
    if (!callData || !callData.twilioSid) return;

    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–∏–≥–Ω–∞–ª Twilio –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–≤–æ–Ω–∫–∞
    // –≠—Ç–æ –≤—ã–∑–æ–≤–µ—Ç webhook /continue/:callId –≥–¥–µ –º—ã –≤–µ—Ä–Ω–µ–º TwiML —Å audio
    this.emit('playback-ready', { callId, twilioSid: callData.twilioSid });
  }

  /**
   * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Say TwiML –¥–ª—è —Ñ–æ–ª–±—ç–∫–∞
   */
  generateSayTwiML(callId, text, voice = 'Polly.Maxim') {
    logger.warn(`üîä Generating Say TwiML fallback with voice: ${voice}`);

    const twiml = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say voice="${voice}" language="ru-RU">${text}</Say>
    <Record 
        action="${TWILIO_CONFIG.serverUrl}/api/webhooks/recording/${callId}"
        method="POST"
        maxLength="60"
        playBeep="false"
        timeout="3"
        trim="trim-silence"  
        finishOnKey="#"
        recordingStatusCallback="${TWILIO_CONFIG.serverUrl}/api/webhooks/recording-status/${callId}"
    />
</Response>`;

    return twiml;
  }

  /**
   * –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–≤–æ–Ω–æ–∫
   */
  async handleCallAnswered(callId) {
    const callData = this.activeCalls.get(callId);
    if (!callData) {
      logger.error(`Call answered but data not found: ${callId}`);
      return { ready: false };
    }

    callData.status = 'answered';

    await Call.findOneAndUpdate(
      { call_id: callId },
      {
        status: 'answered',
        answer_time: new Date(),
      }
    );

    logger.info(`üìû Call answered: ${callId}`);

    const audioData = this.pendingAudio.get(callId);
    if (audioData) {
      logger.info(
        `üéµ Greeting audio ready for call ${callId}: ${audioData.source}`
      );
      return { ready: true, audioType: audioData.source };
    }

    const script = DebtCollectionScripts.getScript(
      'start',
      'positive',
      callData.session.clientData
    );

    logger.warn(
      `‚ö†Ô∏è No greeting audio ready for call ${callId}, using fallback script`
    );
    return { ready: false, script: script.text };
  }

  /**
   * –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–≤–æ–Ω–∫–∞
   */
  async updateCallStatus(callId, status, data = {}) {
    const callData = this.activeCalls.get(callId);
    if (callData) {
      callData.status = status;
      callData.lastActivity = Date.now();
    }

    try {
      const updateData = { status, [`${status}_time`]: new Date(), ...data };
      await Call.findOneAndUpdate({ call_id: callId }, updateData);

      logger.info(`üìû Call ${status}: ${callId}`);
    } catch (error) {
      logger.error(`‚ùå Failed to update call status for ${callId}:`, error);
    }
  }

  /**
   * –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–≤–æ–Ω–∫–∞
   */
  async endCall(callId, result = 'completed', error = null) {
    const callData = this.activeCalls.get(callId);
    if (!callData) {
      logger.warn(`Call data not found for ending call: ${callId}`);
      return;
    }

    const duration = Date.now() - callData.startTime;

    logger.info(
      `üìû Ending call: ${callId}, result: ${result}, duration: ${duration}ms`
    );

    // –û—á–∏—â–∞–µ–º —Ç—Ä–µ–∫–µ—Ä—ã
    this.cleanupCallTrackers(callId);

    this.cleanupCallDetectionResources(callId);

    // –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
    this.activeCalls.delete(callId);
    this.pendingAudio.delete(callId);
    this.conversationStages.delete(callId);

    if (this.isStreamingEnabled) {
      mediaStreamManager.cleanupStream(callId);
      this.streamingMetrics.delete(callId);
      this.pendingTwiml.delete(callId);
    }

    // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    try {
      await Call.findOneAndUpdate(
        { call_id: callId },
        {
          status: result,
          end_time: new Date(),
          duration_ms: duration,
          final_stage: callData.currentStage,
          error_message: error?.message || null,
        }
      );

      logger.info(`‚úÖ Call data saved to database for ${callId}`);
    } catch (dbError) {
      logger.error(`‚ùå Failed to save call data for ${callId}:`, dbError);
    }

    logger.info(`‚úÖ Call cleanup completed: ${callId}`);
  }

  cleanupCallDetectionResources(callId) {
    // –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–æ–ª—á–∞–Ω–∏—è
    silenceHandler.cleanupCallStats(callId);

    // –û—á–∏—â–∞–µ–º —Ç—Ä–µ–∫–∏–Ω–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥)
    this.classificationTracker.delete(callId);

    // –û—á–∏—â–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥)
    this.recordingProcessing.delete(callId);

    logger.info(`üßπ Cleaned up detection resources for call: ${callId}`);
  }

  /**
   * –û—á–∏—Å—Ç–∫–∞ —Ç—Ä–µ–∫–µ—Ä–æ–≤ –∑–≤–æ–Ω–∫–∞
   */
  cleanupCallTrackers(callId) {
    if (this.classificationTracker.has(callId)) {
      const finalStats = this.classificationTracker.get(callId);
      logger.info(
        `üìä Final classification stats for call ${callId}:`,
        finalStats
      );
      this.classificationTracker.delete(callId);
    }

    this.gptFailureCounter.delete(callId);
  }

  /**
   * –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤
   */
  async cleanupStaleCalls() {
    const now = Date.now();
    const maxCallDuration = 10 * 60 * 1000; // 10 –º–∏–Ω—É—Ç
    let cleanedCount = 0;

    for (const [callId, callData] of this.activeCalls.entries()) {
      if (now - callData.startTime > maxCallDuration) {
        logger.warn(`üßπ Cleaning up stale call: ${callId}`);
        await this.endCall(callId, 'timeout');
        cleanedCount++;
      }
    }

    return cleanedCount;
  }

  /**
   * –ù–∞–π—Ç–∏ callId –ø–æ Twilio SID
   */
  findCallIdByTwilioSid(twilioSid) {
    for (const [callId, callData] of this.activeCalls.entries()) {
      if (
        callData.twilioSid === twilioSid ||
        callData.twilioCallSid === twilioSid
      ) {
        logger.info(`‚úÖ Found callId from CallSid: ${callId} -> ${twilioSid}`);
        return callId;
      }
    }

    logger.warn(`‚ö†Ô∏è CallId not found for Twilio SID: ${twilioSid}`);
    return null;
  }

  /**
   * –û–±—Ä–∞–±–æ—Ç–∫–∞ streaming –∞—É–¥–∏–æ (–∞–Ω–∞–ª–æ–≥ processRecording –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤)
   */
  async processStreamingAudio(callId, audioBuffer) {
    const callData = this.activeCalls.get(callId);
    if (!callData) {
      logger.error(
        `Cannot process streaming audio: call data not found for ${callId}`
      );
      return null;
    }

    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    this.setRecordingProcessing(callId, true);

    try {
      const startTime = Date.now();
      logger.info(`üé§ Starting streaming audio processing for call: ${callId}`);

      // 1Ô∏è‚É£ SPEECH-TO-TEXT
      const sttStart = Date.now();

      // –°–æ–∑–¥–∞–µ–º job –¥–ª—è STT
      const sttJob = await sttQueue.add('transcribe', {
        audioBuffer,
        callId,
        format: 'wav',
        language: 'ru-RU',
      });

      const sttResult = await sttJob.finished();

      if (!sttResult || !sttResult.transcription) {
        throw new Error('STT failed or returned empty result');
      }

      const transcription = sttResult.transcription.trim();
      const sttDuration = Date.now() - sttStart;

      logger.info(`üìù STT completed in ${sttDuration}ms: "${transcription}"`);

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—É—Å—Ç—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
      if (transcription.length < 3) {
        logger.info(`ü§´ Empty or too short transcription, ignoring`);
        return null;
      }

      // 2Ô∏è‚É£ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ò –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–í–ï–¢–ê
      const llmStart = Date.now();

      // –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
      const currentStage = callData.currentStage || 'initial';
      const conversationHistory = callData.conversationHistory || [];

      // –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
      const classificationJob = await llmQueue.add('classifyMessage', {
        message: transcription,
        callId,
        clientData: callData.clientData,
        currentStage,
        conversationHistory,
      });

      const classificationResult = await classificationJob.finished();
      const classification = classificationResult.classification || 'neutral';

      logger.info(`üè∑Ô∏è Classification: ${classification}`);

      // –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π
      const repeatCount = this.updateClassificationTracker(
        callId,
        classification
      );

      // –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
      conversationHistory.push(transcription);
      callData.conversationHistory = conversationHistory;

      // 3Ô∏è‚É£ –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–í–ï–¢–ê
      const responseJob = await llmQueue.add('generateResponse', {
        responseContext: {
          callId,
          clientData: callData.clientData,
          clientMessage: transcription,
          classification,
          conversationHistory,
          currentStage,
          repeatCount,
        },
      });

      const responseResult = await responseJob.finished();

      if (!responseResult || !responseResult.success) {
        throw new Error(
          `Response generation failed: ${responseResult?.error || 'Unknown error'}`
        );
      }

      const llmDuration = Date.now() - llmStart;
      logger.info(`üß† LLM processing completed in ${llmDuration}ms`);

      // –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
      conversationHistory.push(responseResult.response);
      callData.conversationHistory = conversationHistory;

      // –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞–¥–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
      if (responseResult.nextStage) {
        callData.currentStage = responseResult.nextStage;
      }

      // 4Ô∏è‚É£ –ì–ï–ù–ï–†–ê–¶–ò–Ø TTS
      const ttsStart = Date.now();

      await this.generateResponseTTS(
        callId,
        responseResult.response,
        'urgent', // –î–ª—è streaming –∏—Å–ø–æ–ª—å–∑—É–µ–º urgent –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        'streaming'
      );

      const ttsDuration = Date.now() - ttsStart;
      const totalDuration = Date.now() - startTime;

      // 5Ô∏è‚É£ –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ú–ï–¢–†–ò–ö
      logger.info(`‚è±Ô∏è Streaming processing metrics for ${callId}:`, {
        stt: `${sttDuration}ms`,
        llm: `${llmDuration}ms`,
        tts: `${ttsDuration}ms`,
        total: `${totalDuration}ms`,
        transcription: transcription.substring(0, 50) + '...',
        response: responseResult.response.substring(0, 50) + '...',
      });

      // 6Ô∏è‚É£ –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ë–î (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
      this.saveConversationTurn(callId, {
        userMessage: transcription,
        classification,
        aiResponse: responseResult.response,
        nextStage: responseResult.nextStage,
        processingTime: totalDuration,
        isStreaming: true,
      }).catch((error) => {
        logger.error(`Failed to save conversation turn: ${error}`);
      });

      return {
        success: true,
        transcription,
        classification,
        response: responseResult.response,
        nextStage: responseResult.nextStage,
        metrics: {
          stt: sttDuration,
          llm: llmDuration,
          tts: ttsDuration,
          total: totalDuration,
        },
      };
    } catch (error) {
      logger.error(`‚ùå Streaming audio processing error for ${callId}:`, error);

      // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º fallback –æ—Ç–≤–µ—Ç
      try {
        await this.generateResponseTTS(
          callId,
          '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.',
          'urgent',
          'error'
        );
      } catch (ttsError) {
        logger.error(`Failed to generate error TTS: ${ttsError}`);
      }

      return {
        success: false,
        error: error.message,
      };
    } finally {
      // –°–Ω–∏–º–∞–µ–º —Ñ–ª–∞–≥ –æ–±—Ä–∞–±–æ—Ç–∫–∏
      this.setRecordingProcessing(callId, false);
    }
  }

  /**
   * –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–≤–æ–Ω–∫–∞ –ø–æ callId
   */
  getCallData(callId) {
    return this.activeCalls.get(callId);
  }

  /**
   * –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–≤–æ–Ω–∫–∞ –ø–æ Twilio SID
   */
  getCallDataByTwilioSid(twilioSid) {
    const callId = this.findCallIdByTwilioSid(twilioSid);
    return callId ? this.activeCalls.get(callId) : null;
  }

  /**
   * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Redirect TwiML (–¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è TTS)
   */
  generateRedirectTwiML(callId) {
    const baseUrl =
      TWILIO_CONFIG.serverUrl ||
      CONFIG.SERVER_URL ||
      `http://localhost:${CONFIG.PORT || 3000}`;

    const twiml = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Pause length="2"/>
    <Redirect method="POST">${baseUrl}/api/webhooks/twiml</Redirect>
</Response>`;

    logger.info(`üîÑ Generating Redirect TwiML for call: ${callId}`);
    return twiml;
  }

  /**
   * –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–≤–æ–Ω–∫–∞ (–¥–ª—è webhooks)
   */
  async handleCallStatus(callId, status, data = {}) {
    const callData = this.activeCalls.get(callId);

    if (!callData) {
      logger.warn(`Call data not found for status update: ${callId}`);
      return;
    }

    switch (status) {
      case 'initiated':
        await this.updateCallStatus(callId, 'initiated');
        logger.info(`üìû Call initiated: ${callId}`);
        break;

      case 'ringing':
        await this.updateCallStatus(callId, 'ringing');
        logger.info(`üìû Call ringing: ${callId}`);
        break;

      case 'in-progress':
      case 'answered':
        await this.updateCallStatus(callId, 'answered');
        logger.info(`üìû Call in progress: ${callId}`);
        break;

      case 'completed':
        const duration = data.duration || 0;
        const sipCode = data.sipCode || '200';

        logger.info(`üìû Call status update: ${callId} - ${status}`, {
          callSid: data.callSid,
          duration,
          sipCode,
        });

        await this.endCall(callId, 'completed');
        logger.info(`üìû Call ended: ${callId} with status: ${status}`);
        break;

      default:
        logger.info(`üìû Call status update: ${callId} - ${status}`);
        await this.updateCallStatus(callId, status, data);
    }
  }

  /**
   * –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∏ –∏–∑ webhook
   */
  async handleRecordingReceived(
    callId,
    recordingUrl,
    recordingDuration,
    digits = null
  ) {
    logger.info(`üé§ Recording received for call: ${callId}`, {
      url: recordingUrl,
      duration: recordingDuration,
    });

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ hang up
    if (digits === 'hangup') {
      logger.info(`üìû Call hung up during recording: ${callId}`);
      await this.endCall(callId, 'completed');
      return;
    }

    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø–∏—Å—å
    return await this.processRecording(callId, recordingUrl, recordingDuration);
  }

  /**
   * –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–ø–∏—Å–∏
   */
  async handleRecordingStatus(callId, status, data = {}) {
    logger.info(`üé§ Recording status update: ${callId} - ${status}`, {
      recordingSid: data.recordingSid,
      url: data.url,
    });

    // –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç—É—Å–æ–≤ –∑–∞–ø–∏—Å–∏
    // –ù–∞–ø—Ä–∏–º–µ—Ä, –æ—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–∏
  }

  /**
   * –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–≤–æ–Ω–∫–∏
   */
  getActiveCalls() {
    const calls = [];
    for (const [callId, callData] of this.activeCalls.entries()) {
      calls.push({
        callId,
        twilioSid: callData.twilioSid || callData.twilioCallSid,
        status: callData.status,
        clientId: callData.clientId,
        currentStage: callData.currentStage,
        startTime: callData.startTime,
        duration: Date.now() - callData.startTime,
      });
    }
    return calls;
  }

  /**
   * –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–≤–æ–Ω–∫–æ–≤
   */
  getCallStatistics() {
    const stats = {
      active: this.activeCalls.size,
      processing: this.recordingProcessing.size,
      pendingAudio: this.pendingAudio.size,
      classifications: {},
      stages: {},
    };

    // –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —ç—Ç–∞–ø–∞–º –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è–º
    for (const [callId, callData] of this.activeCalls.entries()) {
      const stage = callData.currentStage || 'unknown';
      stats.stages[stage] = (stats.stages[stage] || 0) + 1;
    }

    for (const [callId, tracker] of this.classificationTracker.entries()) {
      for (const [classification, count] of Object.entries(tracker)) {
        stats.classifications[classification] =
          (stats.classifications[classification] || 0) + count;
      }
    }

    return stats;
  }

  isRecordingProcessing(callId) {
    return this.recordingProcessing.has(callId);
  }

  // –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–∞—Ä–∫–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏
  setRecordingProcessing(callId, processing = true) {
    if (processing) {
      this.recordingProcessing.set(callId, Date.now()); // ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
      logger.info(`üé§ Marked recording as processing for call: ${callId}`);
    } else {
      this.recordingProcessing.delete(callId);
      logger.info(`‚úÖ Removed processing marker for call: ${callId}`);
    }
  }

  /**
   * –ù–û–í–´–ô: –ü–æ–ª—É—á–∏—Ç—å pending TwiML –¥–ª—è continue webhook
   */
  getPendingTwiml(callId) {
    const twiml = this.pendingTwiml.get(callId);
    if (twiml) {
      this.pendingTwiml.delete(callId);
      return twiml;
    }
    return null;
  }

  /**
   * –ù–û–í–´–ô: –ú–µ—Ç–æ–¥ –¥–ª—è —Å–≤—è–∑–∏ —Å mediaStreamManager
   */
  linkMediaStream(callId, streamSid) {
    const callData = this.activeCalls.get(callId);
    if (callData) {
      callData.streamSid = streamSid;
      logger.info(`üîó Linked media stream ${streamSid} to call ${callId}`);
    }
  }

  /**
   * Test method to verify the manager is working
   */
  test() {
    logger.info('‚úÖ OutboundManager test method called');
    return {
      status: 'working',
      activeCalls: this.activeCalls.size,
      pendingAudio: this.pendingAudio.size,
      timestamp: new Date().toISOString(),
    };
  }
}

// –≠–∫—Å–ø–æ—Ä—Ç singleton instance
export const outboundManager = new OutboundManager();

logger.info('‚úÖ OutboundManager instance created and exported');
