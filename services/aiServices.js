import { OpenAI } from 'openai';
import axios from 'axios';
import { CONFIG } from '../config/index.js';
import { logger } from '../utils/logger.js';
import { File as FormDataFile } from 'formdata-node';

const openai = new OpenAI({
  apiKey: CONFIG.OPENAI_API_KEY,
  timeout: 60000,
  maxRetries: 3,
});

export class AIServices {
  // Speech-to-Text
  static async transcribeAudio(audioBuffer) {
    logger.info('üîç –ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ', {
      bufferSize: audioBuffer?.length || 0,
    });

    console.log(
      'OpenAI API Key:',
      CONFIG.OPENAI_API_KEY?.substring(0, 10) + '...'
    );

    if (!CONFIG.OPENAI_API_KEY) {
      logger.error('‚ùå OpenAI API –∫–ª—é—á –Ω–µ —É–∫–∞–∑–∞–Ω');
      return {
        text: '[SYSTEM: OpenAI –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω]',
        confidence: 0.5,
        timestamp: Date.now(),
        fallback: true,
      };
    }

    try {
      const audioFile = new FormDataFile([audioBuffer], 'recording.wav', {
        type: 'audio/wav',
      });

      logger.info('üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ –≤ OpenAI Whisper', {
        sizeKB: `${(audioBuffer.length / 1024).toFixed(1)} KB`,
        type: 'audio/wav',
      });

      const startTime = Date.now();
      const response = await openai.audio.transcriptions.create({
        file: audioFile,
        model: 'whisper-1',
        language: 'ru',
        response_format: 'json',
      });

      const processingTime = Date.now() - startTime;

      logger.info('‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ', {
        text: response.text,
        length: response.text?.length || 0,
        processingTime: `${processingTime}ms`,
      });

      return {
        text: response.text,
        confidence: 0.95,
        timestamp: Date.now(),
      };
    } catch (error) {
      logger.error('‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏', {
        message: error.message,
        code: error.code,
        status: error.status,
        stack: error.stack?.split('\n')[0],
      });

      if (
        error.message?.includes('Connection error') ||
        error.message?.includes('timeout') ||
        error.message?.includes('ENOTFOUND') ||
        error.message?.includes('network')
      ) {
        logger.warn('üåê –ü—Ä–æ–±–ª–µ–º–∞ —Å —Å–µ—Ç—å—é ‚Äî —Ç–µ—Å—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è...');

        try {
          await this.testNetworkConnectivity();
        } catch (netError) {
          logger.error('üö´ –¢–µ—Å—Ç —Å–µ—Ç–∏ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω', {
            message: netError.message,
          });
        }
      }

      logger.warn('üõ†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é');
      return {
        text: '[SYSTEM: –û—à–∏–±–∫–∞ OpenAI ‚Äî fallback –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω]',
        confidence: 0.3,
        timestamp: Date.now(),
        fallback: true,
        error: error.message,
      };
    }
  }

  static async testNetworkConnectivity() {
    logger.info('üåê –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI...');

    try {
      const response = await axios.get('https://api.openai.com/v1/models', {
        headers: {
          Authorization: `Bearer ${CONFIG.OPENAI_API_KEY}`,
          'User-Agent': 'AI-Call-Backend/1.0',
        },
        timeout: 10000,
      });

      logger.info('‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ', {
        status: response.status,
        dataSample: JSON.stringify(response.data?.data?.[0] || {}),
      });
    } catch (error) {
      logger.error('‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ', {
        message: error.message,
        code: error.code,
        response: error.response?.status,
      });
      throw error;
    }
  }

  static async classifyResponse(text, currentStage, conversationHistory = []) {
    logger.info('üß† –ù–∞—á–∞–ª–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞', {
      inputText: text,
      stage: currentStage,
      history: conversationHistory.slice(-3),
    });

    if (text.includes('[SYSTEM:')) {
      logger.warn('‚ÑπÔ∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è fallback —Ç–µ–∫—Å—Ç–∞');
      return {
        classification: 'positive',
        confidence: 0.7,
        timestamp: Date.now(),
        fallback: true,
      };
    }

    if (!CONFIG.OPENAI_API_KEY) {
      logger.warn('‚ö†Ô∏è –ö–ª—é—á OpenAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è simpleClassify');
      return {
        classification: this.simpleClassify(text),
        confidence: 0.7,
        timestamp: Date.now(),
        fallback: true,
      };
    }

    try {
      const prompt = `
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–Ω–∏–∫–∞ –≤ –¥–∏–∞–ª–æ–≥–µ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞.

–¢–µ–∫—É—â–∏–π —ç—Ç–∞–ø: ${currentStage}
–û—Ç–≤–µ—Ç –¥–æ–ª–∂–Ω–∏–∫–∞: "${text}"
–ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞: ${conversationHistory.slice(-3).join(' | ') || '–Ω–∞—á–∞–ª–æ'}

–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π –æ—Ç–≤–µ—Ç –∫–∞–∫ –æ–¥–∏–Ω –∏–∑:
- positive
- negative
- neutral
- aggressive
- hang_up

–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º.
`;

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: prompt }],
        max_tokens: 10,
        temperature: 0.1,
      });

      const rawResult = response.choices[0]?.message?.content
        ?.trim()
        .toLowerCase();
      const validated = this.validateClassification(rawResult);

      logger.info('‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞', {
        raw: rawResult,
        validated,
      });

      return {
        classification: validated,
        confidence: 0.9,
        timestamp: Date.now(),
      };
    } catch (error) {
      logger.error('‚ùå –û—à–∏–±–∫–∞ LLM –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏', {
        message: error.message,
      });

      return {
        classification: this.simpleClassify(text),
        confidence: 0.7,
        timestamp: Date.now(),
        fallback: true,
      };
    }
  }

  static validateClassification(classification) {
    const valid = ['positive', 'negative', 'neutral', 'aggressive', 'hang_up'];
    return valid.includes(classification) ? classification : 'neutral';
  }

  static simpleClassify(text) {
    const lowerText = text.toLowerCase();

    const rules = [
      {
        type: 'positive',
        pattern:
          /\b(–¥–∞|—Ö–æ—Ä–æ—à–æ|—Å–æ–≥–ª–∞—Å–µ–Ω|–¥–æ–≥–æ–≤–æ—Ä–∏–ª–∏—Å—å|–ª–∞–¥–Ω–æ|–æ–∫–µ–π|–ø–æ–Ω—è—Ç–Ω–æ|–±—É–¥—É|–∑–∞–ø–ª–∞—á—É|–æ–ø–ª–∞—á—É)\b/,
      },
      {
        type: 'negative',
        pattern: /\b(–Ω–µ—Ç|–Ω–µ –±—É–¥—É|–Ω–µ –º–æ–≥—É|–æ—Ç–∫–∞–∑—ã–≤–∞—é—Å—å|–Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ|–¥–µ–Ω–µ–≥ –Ω–µ—Ç)\b/,
      },
      {
        type: 'aggressive',
        pattern: /\b(—Å—É–∫–∞|–±–ª—è—Ç—å|—Ö—É–π|–ø–∏–∑–¥–µ—Ü|–æ—Ç—ä–µ–±–∏—Å—å|–∏–¥–∏ –Ω–∞—Ö—É–π|—É—Ä–æ–¥|–º—É–¥–∞–∫)\b/,
      },
      {
        type: 'hang_up',
        pattern:
          /\b(–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è|–ø–æ–∫–∞|–∫–ª–∞–¥—É —Ç—Ä—É–±–∫—É|–¥–æ –≤—Å—Ç—Ä–µ—á–∏|–≤—Å–µ–≥–æ –¥–æ–±—Ä–æ–≥–æ|–æ—Ç–∫–ª—é—á–∞—é—Å—å)\b/,
      },
    ];

    for (const rule of rules) {
      if (lowerText.match(rule.pattern)) {
        logger.debug(`üß© simpleClassify: —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å ${rule.type}`);
        return rule.type;
      }
    }

    logger.debug('üß© simpleClassify: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî neutral');
    return 'neutral';
  }

  static async synthesizeSpeech(text, options = {}) {
    logger.info('üó£Ô∏è –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏', {
      text,
      options,
    });

    try {
      const ttsManager = (await import('../services/ttsManager.js')).ttsManager;
      return await ttsManager.synthesizeSpeech(text, options);
    } catch (error) {
      logger.error('‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏', {
        message: error.message,
        stack: error.stack?.split('\n')[0],
      });
      throw new Error(`Speech synthesis failed: ${error.message}`);
    }
  }

  /**
   * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ GPT
   */
  static async generateResponse(prompt, options = {}) {
    logger.info('ü§ñ –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ GPT', {
      promptLength: prompt.length,
      options,
    });

    if (!CONFIG.OPENAI_API_KEY) {
      logger.error('‚ùå OpenAI API –∫–ª—é—á –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤');
      throw new Error('OpenAI API key not configured');
    }

    if (!CONFIG.ENABLE_GPT_RESPONSES) {
      logger.warn('‚ö†Ô∏è GPT –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö');
      throw new Error('GPT response generation disabled');
    }

    try {
      const {
        maxTokens = CONFIG.GPT_MAX_RESPONSE_TOKENS || 100,
        temperature = CONFIG.GPT_TEMPERATURE_RESPONSE || 0.7,
        model = CONFIG.GPT_MODEL_RESPONSE || 'gpt-3.5-turbo',
      } = options;

      const startTime = Date.now();

      const response = await openai.chat.completions.create({
        model,
        messages: [{ role: 'user', content: prompt }],
        max_tokens: maxTokens,
        temperature,
        timeout: CONFIG.GPT_TIMEOUT_RESPONSE || 15000,
        stop: ['\n\n', '–ö–ª–∏–µ–Ω—Ç:', '–†–æ—Å—Ç–∏–∫:'], // –û—Å—Ç–∞–Ω–æ–≤–æ—á–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
      });

      const processingTime = Date.now() - startTime;
      const generatedText = response.choices[0]?.message?.content?.trim();

      logger.info('‚úÖ GPT –æ—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω', {
        text: generatedText,
        length: generatedText?.length || 0,
        processingTime: `${processingTime}ms`,
        model,
        tokensUsed: response.usage?.total_tokens || 0,
      });

      // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
      const validationResult = this.validateGPTResponse(generatedText);

      if (!validationResult.isValid) {
        logger.warn('‚ö†Ô∏è GPT –æ—Ç–≤–µ—Ç –Ω–µ –ø—Ä–æ—à—ë–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é', validationResult);
        throw new Error(
          `GPT response validation failed: ${validationResult.reason}`
        );
      }

      return {
        text: generatedText,
        confidence: 0.85,
        processingTime,
        tokensUsed: response.usage?.total_tokens || 0,
        model,
        timestamp: Date.now(),
      };
    } catch (error) {
      logger.error('‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ GPT –æ—Ç–≤–µ—Ç–∞', {
        message: error.message,
        code: error.code,
        status: error.status,
        stack: error.stack?.split('\n')[0],
      });

      // –†–µ—Ç—Ä–∞–π –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö
      if (
        this.shouldRetryGPTRequest(error) &&
        (options.retryCount || 0) < CONFIG.GPT_RETRY_ATTEMPTS
      ) {
        logger.info(
          `üîÑ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ GPT –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (${(options.retryCount || 0) + 1}/${CONFIG.GPT_RETRY_ATTEMPTS})`
        );

        await this.delay(1000 * Math.pow(2, options.retryCount || 0)); // Exponential backoff

        return this.generateResponse(prompt, {
          ...options,
          retryCount: (options.retryCount || 0) + 1,
        });
      }

      throw new Error(`GPT response generation failed: ${error.message}`);
    }
  }

  /**
   * –í–∞–ª–∏–¥–∞—Ü–∏—è GPT –æ—Ç–≤–µ—Ç–∞
   */
  static validateGPTResponse(text) {
    if (!text || typeof text !== 'string') {
      return {
        isValid: false,
        reason: 'Empty or invalid response',
      };
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã
    if (
      text.length < CONFIG.MIN_RESPONSE_LENGTH ||
      text.length > CONFIG.MAX_RESPONSE_LENGTH
    ) {
      return {
        isValid: false,
        reason: `Invalid length: ${text.length} (min: ${CONFIG.MIN_RESPONSE_LENGTH}, max: ${CONFIG.MAX_RESPONSE_LENGTH})`,
      };
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    if (
      text.includes('[SYSTEM') ||
      text.includes('AI:') ||
      text.includes('GPT:')
    ) {
      return {
        isValid: false,
        reason: 'Contains system messages',
      };
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
    const forbiddenWords = [
      '–±–ª—è—Ç—å',
      '—Å—É–∫–∞',
      '—Ö—É–π',
      '–ø–∏–∑–¥–∞',
      '–µ–±–∞—Ç—å',
      '—É–±—å—é',
      '—É–±–∏—Ç—å',
      '–Ω–∞–π–¥—É —Ç–µ–±—è',
      '–ø—Ä–∏–µ–¥—É –∫ —Ç–µ–±–µ',
    ];

    const hasForbiddenWords = forbiddenWords.some((word) =>
      text.toLowerCase().includes(word)
    );

    if (hasForbiddenWords) {
      return {
        isValid: false,
        reason: 'Contains forbidden words',
      };
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Ä–æ–ª–∏
    const offTopicKeywords = [
      '–ø–æ–≥–æ–¥–∞',
      '—Å–ø–æ—Ä—Ç',
      '—Ñ—É—Ç–±–æ–ª',
      '–ø–æ–ª–∏—Ç–∏–∫–∞',
      '–Ω–æ–≤–æ—Å—Ç–∏',
      '—Ä–µ—Ü–µ–ø—Ç',
      '—Ñ–∏–ª—å–º',
      '–º—É–∑—ã–∫–∞',
      '–∏–≥—Ä–∞',
    ];

    const isOffTopic = offTopicKeywords.some((keyword) =>
      text.toLowerCase().includes(keyword)
    );

    if (isOffTopic) {
      return {
        isValid: false,
        reason: 'Off-topic content detected',
      };
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–∏–∞–ª–æ–≥–æ–≤)
    if (/–ö–ª–∏–µ–Ω—Ç:|–†–æ—Å—Ç–∏–∫:|AI:|GPT:/.test(text)) {
      return {
        isValid: false,
        reason: 'Contains dialogue structure',
      };
    }

    return {
      isValid: true,
      length: text.length,
    };
  }

  /**
   * –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ—Ç—Ä–∞—è –¥–ª—è GPT –∑–∞–ø—Ä–æ—Å–∞
   */
  static shouldRetryGPTRequest(error) {
    const retryableErrors = [
      'timeout',
      'network',
      'ECONNRESET',
      'ENOTFOUND',
      'rate_limit_exceeded',
      'server_error',
    ];

    return retryableErrors.some(
      (errorType) =>
        error.message?.toLowerCase().includes(errorType) ||
        error.code?.toLowerCase().includes(errorType)
    );
  }

  /**
   * –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Ä–µ—Ç—Ä–∞–µ–≤
   */
  static delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }

  /**
   * –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPT
   */
  static getGPTUsageStats() {
    // –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –∫ –≤–Ω–µ—à–Ω–µ–π —Å–∏—Å—Ç–µ–º–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    return {
      totalRequests: this.gptStats?.totalRequests || 0,
      successfulRequests: this.gptStats?.successfulRequests || 0,
      failedRequests: this.gptStats?.failedRequests || 0,
      averageResponseTime: this.gptStats?.averageResponseTime || 0,
      totalTokensUsed: this.gptStats?.totalTokensUsed || 0,
      lastRequestTime: this.gptStats?.lastRequestTime || null,
    };
  }

  /**
   * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ GPT (–¥–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –∫–ª–∞—Å—Å–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
   */
  static initGPTStats() {
    this.gptStats = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      totalResponseTime: 0,
      totalTokensUsed: 0,
      lastRequestTime: null,
    };
  }

  /**
   * –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ GPT
   */
  static updateGPTStats(success, responseTime, tokensUsed) {
    if (!this.gptStats) this.initGPTStats();

    this.gptStats.totalRequests++;
    this.gptStats.lastRequestTime = Date.now();

    if (success) {
      this.gptStats.successfulRequests++;
      this.gptStats.totalResponseTime += responseTime;
      this.gptStats.totalTokensUsed += tokensUsed || 0;
      this.gptStats.averageResponseTime =
        this.gptStats.totalResponseTime / this.gptStats.successfulRequests;
    } else {
      this.gptStats.failedRequests++;
    }
  }
}
